# RAG Faciliatated Medical Question Answering

## Summary

Accurate machine **medical question answering** can provide actionable insights for caregivers and reduce their workload. **Large language models (LLMs)**, conbined with the concept of **retrieval-augmented generation (RAG) inspired endeavors on machine question answering**, especially **in domains where knowledge is updated rapidly**, such as **biomedical research**. **This project aims to investigate the effectiveness of applying RAG on medical question answering. MedQuAD, a medical question answer dataset containing more than 200 thousand question-answer pairs**, was used for the study. Accuracy and F-1 score were applied to evaluate the generated yes-no answers. ROUGE-L and BLEU scores were used to assess the quality of generated long answers. **With correctly paired question-document as input**, the **test accuracy and F-1 score achieved 74.49 and 81.41**, higher than accuracy and achieved using questions alone (63.71 and 77.01 respectively).  The **ROUGE-L and BLEU scores** using the correct question-document pair as input **were 12.66 and 13.72**, higher than using questions with retrieved documents and questions only as input. **The results show the potential of RAG to improve the performance of machine medical question answering**. Further research is needed to increase accuracy for clinical use.
